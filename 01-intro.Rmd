# Introduction {#intro}

What is machine learning (ML)? Essentially, machine learning teaches computer models to look for patterns or make predictions. You can think of machine learning models as finding underlying formulas from which the data come. To solve for such formulas, many, many mathematical calculations are involved. As we human beings are prone to mistakes for repetitive task, a more effective way to work with data is to identify a framework and give the framework and data to a computer model. The computer is best at repeating meticulous calculations to find a best guess based on our believes of the system and the data we observed.  

Even though ML models are commonly considered black boxes (or some might say opaque boxes), they are not necessarily so. Many ML methods lend easily to interpretation. Random Forests, for example, is a powerful method that provides important variables, even if a straightforward explanation that can come from a linear model is unavailable. Below we introduce the two main branches of machine learning.   

## Supervised Learning  

Simply put, supervised learning is when there are true answers for the model. For example, if we want to use environmental traits (temperature, precipitation, chemical composition) to predict algal bloom. In a dataset that records such activities, the observed growths are the "true" answers. The model can then use the predictors to make predictions, and the comparison between the predictions and the observations/truth can measure how well the model performs.  

## Unsupervised Learning  

Unsupervised learning, on the other hand, performs tasks that do not have correct/true answers. For example, for a group of chemicals, some might have more similar traits than the others. Unsupervised learning can perform clustering to find such groupings. This task is considered unsupervised, because the groupings might depend on the context. One could imagine that clustering can be performed first, and the groupings are used as the predictors instead of the individual chemicals. This way the dimension can be reduced, assuming that the number of groups is smaller than the number of chemicals.  

## Online Resources  

If you feel overwhelmed about the differences in ML models, you are not alone! The sheer number of ML models attests to the power and versatility of machine learning. Search *machine learning models cheat sheet* and you will find some concise resources out there. Here are two that provide useful information. 

* [Which machine learning algorithm should I use](https://blogs.sas.com/content/subconsciousmusings/2020/12/09/machine-learning-algorithm-use/) by SAS blogs.
* [Machine Learning Cheat Sheet](https://www.datacamp.com/cheat-sheet/machine-learning-cheat-sheet?utm_source=google&utm_medium=paid_search&utm_campaignid=19589720830&utm_adgroupid=157098107695&utm_device=c&utm_keyword=&utm_matchtype=&utm_network=g&utm_adpostion=&utm_creative=698229375346&utm_targetid=dsa-2264919291829&utm_loc_interest_ms=&utm_loc_physical_ms=9009732&utm_content=DSA~blog~Julia&utm_campaign=230119_1-sea~dsa~tofu_2-b2c_3-us_4-prc_5-na_6-na_7-le_8-pdsh-go_9-na_10-na_11-na-may24&gad_source=1&gclid=Cj0KCQjw6PGxBhCVARIsAIumnWai3I4X4UtrhM_2dA1pUpmAmC-iErsp57Cv6p4fEQugIVbGrx1VT2YaAsr7EALw_wcB) by Datacamp. 

## Further Reading  

If you would like to learn more, the book *An Introduction to Statistical Learning* by @james2013introduction is a great resource! This book provides a wealth of information about machine learning models; further, the authors assume that the readers are mainly interested in applying, rather than studying, ML models. The four premises offered by the authors, listed on pp 8-9 of the version about R, demonstrate the practical focus of the book:

1. Many statistical learning methods are relevant and useful in a wide range of academic and non-academic disciplines, beyond just the statistical sciences. 
2. Statistical learning should not be viewed as a series of black boxes.
3. While it is important to know what job is performed by each cog, it is not necessary to have the skills to construct the machine inside the box! 
4. We presume that the reader is interested in applying statistical learning methods to real-world problems.

There are free PDF versions with applications in R and Python [here](https://www.statlearning.com/). Be sure to check it out if you are interested in learning more about machine learning models!  

```{r nice-fig, fig.cap='Here is a nice figure!', out.width='80%', fig.asp=.75, fig.align='center', include = F}
# You can label chapter and section titles using `{#label}` after them, e.g., we can reference Chapter \@ref(intro). If you do not manually label them, there will be automatic labels anyway, e.g., Chapter \@ref(methods).

# Figures and tables with captions will be placed in `figure` and `table` environments, respectively.

par(mar = c(4, 4, .1, .1))
plot(pressure, type = 'b', pch = 19)
```



```{r nice-tab, tidy=FALSE, include = F}
# Reference a figure by its code chunk label with the `fig:` prefix, e.g., see Figure \@ref(fig:nice-fig). Similarly, you can reference tables generated from `knitr::kable()`, e.g., see Table \@ref(tab:nice-tab).
knitr::kable(
  head(iris, 20), caption = 'Here is a nice table!',
  booktabs = TRUE
)
# You can write citations, too. For example, we are using the **bookdown** package [@R-bookdown] in this sample book, which was built on top of R Markdown and **knitr** [@xie2015].
```


