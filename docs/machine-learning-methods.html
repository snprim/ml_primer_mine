<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 5 Machine Learning Methods | Machine Learning Guidelines for Natural Resource Management Practitioners</title>
<meta name="author" content="Shih-Ni Prim and Natalie Nelson">
<meta name="description" content="Here we discuss some machine learning methods you might find useful. Although linear regression models are commonly used, we skip it because it is well understood and many online resources can be...">
<meta name="generator" content="bookdown 0.39 with bs4_book()">
<meta property="og:title" content="Chapter 5 Machine Learning Methods | Machine Learning Guidelines for Natural Resource Management Practitioners">
<meta property="og:type" content="book">
<meta property="og:description" content="Here we discuss some machine learning methods you might find useful. Although linear regression models are commonly used, we skip it because it is well understood and many online resources can be...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 5 Machine Learning Methods | Machine Learning Guidelines for Natural Resource Management Practitioners">
<meta name="twitter:description" content="Here we discuss some machine learning methods you might find useful. Although linear regression models are commonly used, we skip it because it is well understood and many online resources can be...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Machine Learning Guidelines for Natural Resource Management Practitioners</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Motivation</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">2</span> Introduction</a></li>
<li><a class="" href="data.html"><span class="header-section-number">3</span> Data</a></li>
<li><a class="" href="evaluation.html"><span class="header-section-number">4</span> Evaluation</a></li>
<li><a class="active" href="machine-learning-methods.html"><span class="header-section-number">5</span> Machine Learning Methods</a></li>
<li><a class="" href="workflow-demonstration.html"><span class="header-section-number">6</span> Workflow Demonstration</a></li>
<li><a class="" href="case-studies.html"><span class="header-section-number">7</span> Case Studies</a></li>
<li><a class="" href="ethical-considerations.html"><span class="header-section-number">8</span> Ethical Considerations</a></li>
<li><a class="" href="appendix.html"><span class="header-section-number">9</span> Appendix</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="machine-learning-methods" class="section level1" number="5">
<h1>
<span class="header-section-number">5</span> Machine Learning Methods<a class="anchor" aria-label="anchor" href="#machine-learning-methods"><i class="fas fa-link"></i></a>
</h1>
<p>Here we discuss some machine learning methods you might find useful. Although linear regression models are commonly used, we skip it because it is well understood and many online resources can be easily located.</p>
<div id="tree-based-methods" class="section level2" number="5.1">
<h2>
<span class="header-section-number">5.1</span> Tree-based Methods<a class="anchor" aria-label="anchor" href="#tree-based-methods"><i class="fas fa-link"></i></a>
</h2>
<p>Tree-based methods are popular for their ease for interpretation. Essentially, the algorithm tries to split the data into subsets by finding the most significant (or consequential) variables in a way that reduces the prediction error the most. For example, in the graph below, the variable that helps reduce prediction error at the first level is gender. In other words, the property of being male or female can greatly help the algorithm predict the survival of passengers on Titanic.</p>
<div class="float">
<img src="images/Decision_Tree.jpg" alt="By Gilgoldm - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=90405437"><div class="figcaption">By Gilgoldm - Own work, CC BY-SA 4.0, <a href="https://commons.wikimedia.org/w/index.php?curid=90405437" class="uri">https://commons.wikimedia.org/w/index.php?curid=90405437</a>
</div>
</div>
<p>Decision trees are easy to use but not very accurate for complex data; however, we can go beyond one tree. If we use multiple trees and, for instance, take the average of the predictions of all the trees, we can improve the performance. This is the idea of ensemble methods. One of the ensemble methods, Random Forests, is commonly used, including in natural resources management, and quite accurate for many kinds of data. So next we’ll dive into this one method.</p>
<div id="random-forests" class="section level3" number="5.1.1">
<h3>
<span class="header-section-number">5.1.1</span> Random Forests<a class="anchor" aria-label="anchor" href="#random-forests"><i class="fas fa-link"></i></a>
</h3>
<p>For Random Forests, the algorithm randomly selects a smaller number, say <span class="math inline">\(m\)</span>, of predictors from the total number, say <span class="math inline">\(p\)</span>, each time a tree is being fit. This process is repeated many times, for example, <span class="math inline">\(500\)</span> times. The average (for continuous responses) or the majority votes (for discrete responses) of the predictions from the individual trees are used as final predictions. By randomly choosing a subset of predictors each time, Random Forests can avoid relying on the same variables every time and prevent overfitting.</p>
<p>Even though coefficients of each predictors are not available for random forests, you can easily get the important variables and at least know which variables are more important for predicting the response. You can also use Random Forests as a tool for variable selection and then use a different method to fit the model on a subset of predictors chosen by Random Forests.</p>
<p>See <a href="workflow-demonstration.html#workflow-demonstration">Workflow Demonstration</a> for examples of Random Forests models.</p>
</div>
<div id="other-ensemble-tree-methods" class="section level3" number="5.1.2">
<h3>
<span class="header-section-number">5.1.2</span> Other Ensemble Tree Methods<a class="anchor" aria-label="anchor" href="#other-ensemble-tree-methods"><i class="fas fa-link"></i></a>
</h3>
<p>Other ensemble tree methods include boosting and bagging. If you are interested, take a look at Chapter 8 (Tree-Based Methods) of <em>An Introduction to Statistical Learning</em> by <span class="citation">James et al. (<a href="references.html#ref-james2013introduction">2013</a>)</span>.</p>
</div>
</div>
<div id="neural-network" class="section level2" number="5.2">
<h2>
<span class="header-section-number">5.2</span> Neural Network<a class="anchor" aria-label="anchor" href="#neural-network"><i class="fas fa-link"></i></a>
</h2>
<p>Neural network has been enjoying its popularity. A neural network model is composed of an input layer, some hidden layers, and an output layer, as seen below. There is only one hidden layer below. When there are enough hidden layers, the model is then called deep learning.</p>
<div class="float">
<img src="images/Colored_neural_network.svg.png" alt="By Glosser.ca - Own work, Derivative of File: Artificial neural network.svg, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=24913461"><div class="figcaption">By Glosser.ca - Own work, Derivative of File: Artificial neural network.svg, CC BY-SA 3.0, <a href="https://commons.wikimedia.org/w/index.php?curid=24913461" class="uri">https://commons.wikimedia.org/w/index.php?curid=24913461</a>
</div>
</div>
<p>So the input layer is the observed predictors, and each of the hidden layers has nodes that contain coefficients. You can think of these coefficients similar to those for linear models, except they do not have linear relationships with the observed predictors. These values are derived as the best fit between data and some kind of cost function; essentially, these values are meant to minimize the differences between observed outcome and predictions. When the values from one hidden layer are passed onto the next layer, a nonlinear activation function called <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">ReLU</a> is commonly used. If the task is classification, the layer right before output is often an algorithm to turn the values into predicted class. While neural network is a powerful ML model, the values in the nodes in the hidden layers are not interpretable. So this indeed is a black-box method. For interested readers, check out Chapter 10 Deep Learning in <span class="citation">James et al. (<a href="references.html#ref-james2013introduction">2013</a>)</span> (<em>An Introduction to Statistical Learning</em>).</p>
</div>
<div id="gaussian-process-gp" class="section level2" number="5.3">
<h2>
<span class="header-section-number">5.3</span> Gaussian Process (GP)<a class="anchor" aria-label="anchor" href="#gaussian-process-gp"><i class="fas fa-link"></i></a>
</h2>
<p>Another ML method that could be useful for natural resource management type of research is Gaussian Process. This method, commonly called kriging in spatial statistics, is non-parametric, which sounds like there are no parameters in the model but in fact means there can be an infinite number of parameters. (Of course in any real model we’ll have finite parameters, but that’s the idea.) The fact that the parameters can increase towards infinity tells us that this is a flexible model. Essentially, for a GP model, and here I quote from Chapter 5 of Gramacy’s <em>Surrogates</em>, “any finite collection of realizations (i.e. <span class="math inline">\(n\)</span> observations) is modeled as having a multivariate normal (MVN) distribution.” In other words, the model tries to learn information from similar items, judging from some kind of distance from each other. MVN has some great properties. And, when there is a new data point, all the observed data points can be used to make prediction for it.</p>
<p>GP is widely used in the machine learning, computer experiments, and spatial statistics communities. There are ready-made R packages, such as <code>GpGp</code> and <code>deepgp</code>. It’s also easy to use in Python. Chapter 5 (<a href="https://bookdown.org/rbg/surrogates/chap5.html">“Gaussian Process Regression”</a>) of the book <em>Surrogates</em> by <span class="citation">Gramacy (<a href="references.html#ref-gramacy2020surrogates">2020</a>)</span> is a great resource if you are interested in learning more about Gaussian process! If you would like to see some theory of GP, check out another classic book <a href="https://gaussianprocess.org/gpml/"><em>Gaussian Processes for Machine learning</em></a> by <span class="citation">Rasmussen and Williams (<a href="references.html#ref-CR2006gp">2006</a>)</span>.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="evaluation.html"><span class="header-section-number">4</span> Evaluation</a></div>
<div class="next"><a href="workflow-demonstration.html"><span class="header-section-number">6</span> Workflow Demonstration</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#machine-learning-methods"><span class="header-section-number">5</span> Machine Learning Methods</a></li>
<li>
<a class="nav-link" href="#tree-based-methods"><span class="header-section-number">5.1</span> Tree-based Methods</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#random-forests"><span class="header-section-number">5.1.1</span> Random Forests</a></li>
<li><a class="nav-link" href="#other-ensemble-tree-methods"><span class="header-section-number">5.1.2</span> Other Ensemble Tree Methods</a></li>
</ul>
</li>
<li><a class="nav-link" href="#neural-network"><span class="header-section-number">5.2</span> Neural Network</a></li>
<li><a class="nav-link" href="#gaussian-process-gp"><span class="header-section-number">5.3</span> Gaussian Process (GP)</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Machine Learning Guidelines for Natural Resource Management Practitioners</strong>" was written by Shih-Ni Prim and Natalie Nelson. It was last built on 2024-05-16.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
