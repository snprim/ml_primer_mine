<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 4 Evaluation | Machine Learning Guidelines for Natural Resource Management Practitioners</title>
<meta name="author" content="Shih-Ni Prim and Natalie Nelson">
<meta name="description" content="4.1 Training vs Testing We should first address the concepts of training and testing. Instead of using the entire data, it is common to split the dataset into a training set and a testing set....">
<meta name="generator" content="bookdown 0.39 with bs4_book()">
<meta property="og:title" content="Chapter 4 Evaluation | Machine Learning Guidelines for Natural Resource Management Practitioners">
<meta property="og:type" content="book">
<meta property="og:description" content="4.1 Training vs Testing We should first address the concepts of training and testing. Instead of using the entire data, it is common to split the dataset into a training set and a testing set....">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 4 Evaluation | Machine Learning Guidelines for Natural Resource Management Practitioners">
<meta name="twitter:description" content="4.1 Training vs Testing We should first address the concepts of training and testing. Instead of using the entire data, it is common to split the dataset into a training set and a testing set....">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Machine Learning Guidelines for Natural Resource Management Practitioners</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Motivation</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">2</span> Introduction</a></li>
<li><a class="" href="data.html"><span class="header-section-number">3</span> Data</a></li>
<li><a class="active" href="evaluation.html"><span class="header-section-number">4</span> Evaluation</a></li>
<li><a class="" href="machine-learning-methods.html"><span class="header-section-number">5</span> Machine Learning Methods</a></li>
<li><a class="" href="workflow-demonstration.html"><span class="header-section-number">6</span> Workflow Demonstration</a></li>
<li><a class="" href="case-studies.html"><span class="header-section-number">7</span> Case Studies</a></li>
<li><a class="" href="ethical-considerations.html"><span class="header-section-number">8</span> Ethical Considerations</a></li>
<li><a class="" href="appendix.html"><span class="header-section-number">9</span> Appendix</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="evaluation" class="section level1" number="4">
<h1>
<span class="header-section-number">4</span> Evaluation<a class="anchor" aria-label="anchor" href="#evaluation"><i class="fas fa-link"></i></a>
</h1>
<div id="training-vs-testing" class="section level2" number="4.1">
<h2>
<span class="header-section-number">4.1</span> Training vs Testing<a class="anchor" aria-label="anchor" href="#training-vs-testing"><i class="fas fa-link"></i></a>
</h2>
<p>We should first address the concepts of training and testing. Instead of using the entire data, it is common to split the dataset into a training set and a testing set. Typically people use percentages such as 70% vs 30% or 80% vs 20%. The idea is to use only, say, 80% of the data for training, which means to run the select model on this part of data. Then you have a model with some coefficients (you can think of them as slopes) and test such results on the testing set to see how well the model performs. Since the part of the data for testing is not used in training, there is no double dipping. Sometimes people split the dataset into three sets: training, testing, and validation. So the trained models are used on the testing set for model selection. Then the validation set is used only once at the end to gauge how the model should perform if thereâ€™s new data.</p>
</div>
<div id="metrics" class="section level2" number="4.2">
<h2>
<span class="header-section-number">4.2</span> Metrics<a class="anchor" aria-label="anchor" href="#metrics"><i class="fas fa-link"></i></a>
</h2>
<div id="numerical-responses" class="section level3" number="4.2.1">
<h3>
<span class="header-section-number">4.2.1</span> Numerical Responses<a class="anchor" aria-label="anchor" href="#numerical-responses"><i class="fas fa-link"></i></a>
</h3>
<p>The most common metrics for numerical responses include mean squared errors (MSE), bias, and <span class="math inline">\(R^2\)</span> (or adjusted <span class="math inline">\(R^2\)</span>). The way to calculate MSE is:
<span class="math display">\[MSE = \frac{1}{n} \sum_{i=1}^n \bigg( \hat{y}_i - y_i \bigg)^2,\]</span>
where <span class="math inline">\(\hat{y}_i\)</span> is the predicted outcome of the <span class="math inline">\(i^{th}\)</span> observation and <span class="math inline">\(y_i\)</span> is the <span class="math inline">\(i^{th}\)</span> observed outcome. The metric shows, on average, the squared distance between predictions and true responses. Bias is calculated as
<span class="math display">\[Bias = \frac{1}{n} \sum_{i=1}^n \bigg( \hat{y}_i - y \bigg).\]</span>
The two metrics seem similar, but they reveal different aspects of model performance. In general, bias shows if the predictions are centered around the truth, while the MSE shows whether the predictions are centered around the truth <em>and</em> how far the predictions are from the truth. If the bias is zero, it means that the mean prediction goes towards the truth as the sample size increases to infinity. This is naturally a desired property, but you might be surprised that sometimes we are willing to accept some bias to reduce the variance.</p>
<p>One important formula is
<span class="math display">\[MSE = Bias^2 + Variance,\]</span>
where
<span class="math display">\[Variance = \frac{1}{n} \sum_{i=1}^n \bigg( \hat{y}_i - E(\hat{y}) \bigg)^2\]</span>
and
<span class="math display">\[E(\hat{y}) = \frac{1}{n} \sum_{i=1}^n \hat{y}_i.\]</span>
We skip the derivation here, but the interested readers can find the derivation readily online. The formula tells us that, if the MSE is large but the bias is small, this means the model has a large variance. This is to say, if you fit the model multiple times, it has quite different results. These formulas might seem too technical, but the message is important. There is a trade-off between bias and variance; in other words, there is no free lunch. A balance between bias and variance is where many methods strive to achieve.</p>
</div>
<div id="categorical-responses" class="section level3" number="4.2.2">
<h3>
<span class="header-section-number">4.2.2</span> Categorical Responses<a class="anchor" aria-label="anchor" href="#categorical-responses"><i class="fas fa-link"></i></a>
</h3>
<p>When the responses are categorical, a common way to measure the performance is a confusion matrix, which shows the numbers of predictions that are correct or incorrect. See some examples in <a href="workflow-demonstration.html#workflow-demonstration">Workflow Demonstration</a>. Other metrics include sensitivity, specificity, precision, recall, and other metrics that try to combine these metrics to present a one-number summary.</p>
</div>
</div>
<div id="overfitting" class="section level2" number="4.3">
<h2>
<span class="header-section-number">4.3</span> Overfitting<a class="anchor" aria-label="anchor" href="#overfitting"><i class="fas fa-link"></i></a>
</h2>
<p>Overfitting means that the model can make good predictions with the available data, but it cannot generalize well on new data. It is like if a student memorizes all the past exam questions without really studying the materials, then, on the exam, the student can do really well on questions coming from past exams but might do poorly on questions never seen before. Splitting data into training and testing is one strategy to avoid overfitting. Certain ML methods are less likely to overfit, such as neural networks. And there are some more strategies, such as early stopping, that can be used. Our point here is to be aware of this potential pitfall of machine learning methods.</p>
</div>
<div id="cross-validation" class="section level2" number="4.4">
<h2>
<span class="header-section-number">4.4</span> Cross Validation<a class="anchor" aria-label="anchor" href="#cross-validation"><i class="fas fa-link"></i></a>
</h2>
<p>One very standard way of evaluation is <span class="math inline">\(k\)</span>-fold cross validation, commonly with <span class="math inline">\(k=5\)</span> or <span class="math inline">\(k=10\)</span>. The idea is simple. Divide the data into <span class="math inline">\(k\)</span> groups. Each time, choose <span class="math inline">\(k-1\)</span> groups for training, fit the model on the last group, which is the test data, and calculate the desired metrics, such as MSE.</p>
<p>This way, although less data is used for training, the metrics should be more accurate, because now we are not using the same data points for training and testing. Using metrics from cross validation for model selection can ensure that your model does not overfit.</p>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-8"></span>
<img src="images/K-fold_cross_validation_EN.svg" alt="Image Source: https://en.wikipedia.org/wiki/Cross-validation_(statistics)"><p class="caption">
Figure 4.1: Image Source: <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)" class="uri">https://en.wikipedia.org/wiki/Cross-validation_(statistics)</a>
</p>
</div>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="data.html"><span class="header-section-number">3</span> Data</a></div>
<div class="next"><a href="machine-learning-methods.html"><span class="header-section-number">5</span> Machine Learning Methods</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#evaluation"><span class="header-section-number">4</span> Evaluation</a></li>
<li><a class="nav-link" href="#training-vs-testing"><span class="header-section-number">4.1</span> Training vs Testing</a></li>
<li>
<a class="nav-link" href="#metrics"><span class="header-section-number">4.2</span> Metrics</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#numerical-responses"><span class="header-section-number">4.2.1</span> Numerical Responses</a></li>
<li><a class="nav-link" href="#categorical-responses"><span class="header-section-number">4.2.2</span> Categorical Responses</a></li>
</ul>
</li>
<li><a class="nav-link" href="#overfitting"><span class="header-section-number">4.3</span> Overfitting</a></li>
<li><a class="nav-link" href="#cross-validation"><span class="header-section-number">4.4</span> Cross Validation</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Machine Learning Guidelines for Natural Resource Management Practitioners</strong>" was written by Shih-Ni Prim and Natalie Nelson. It was last built on 2024-05-16.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
