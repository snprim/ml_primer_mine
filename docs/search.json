[{"path":"index.html","id":"motivation","chapter":"1 Motivation","heading":"1 Motivation","text":"machine learning (ML) becoming ever powerful, noted ML widely used environmental studies. Process based models might preferred, can costly ML provides wide variety tools explored. booklet meant provide concise guide natural resource management practitioners. book serves staring point rather comprehensive resource, practitioners can basic understanding ML works utilize analyze data answer research questions. also provide case studies, R code, links online resources help readers journey gaining one powerful tool becoming omnipresent research world.","code":""},{"path":"intro.html","id":"intro","chapter":"2 Introduction","heading":"2 Introduction","text":"machine learning (ML)? Essentially, machine learning teaches computer models look patterns make predictions. can think machine learning models finding underlying formulas data come. solve formulas, many, many mathematical calculations involved. human beings prone mistakes repetitive task, effective way work data identify framework give framework data computer model. computer best repeating meticulous calculations find best guess based believes system data observed.Even though ML models commonly considered black boxes (might say opaque boxes), necessarily . Many ML methods lend easily interpretation. Random Forests, example, powerful method provides important variables, even straightforward explanation can come linear model unavailable. introduce two main branches machine learning.","code":""},{"path":"intro.html","id":"supervised-learning","chapter":"2 Introduction","heading":"2.1 Supervised Learning","text":"Simply put, supervised learning true answers model. example, want use environmental traits (temperature, precipitation, chemical composition) predict algal bloom. dataset records activities, observed growths “true” answers. model can use predictors make predictions, comparison predictions observations/truth can measure well model performs.","code":""},{"path":"intro.html","id":"unsupervised-learning","chapter":"2 Introduction","heading":"2.2 Unsupervised Learning","text":"Unsupervised learning, hand, performs tasks correct/true answers. example, group chemicals, might similar traits others. Unsupervised learning can perform clustering find groupings. task considered unsupervised, groupings might depend context. One imagine clustering can performed first, groupings used predictors instead individual chemicals. way dimension can reduced, assuming number groups smaller number chemicals.","code":""},{"path":"intro.html","id":"online-resources","chapter":"2 Introduction","heading":"2.3 Online Resources","text":"feel overwhelmed differences ML models, alone! sheer number ML models attests power versatility machine learning. Search machine learning models cheat sheet find concise resources . two provide useful information.machine learning algorithm use SAS blogs.Machine Learning Cheat Sheet Datacamp.","code":""},{"path":"intro.html","id":"further-reading","chapter":"2 Introduction","heading":"2.4 Further Reading","text":"like learn , book Introduction Statistical Learning James et al. (2013) great resource! book provides wealth information machine learning models; , authors assume readers mainly interested applying, rather studying, ML models. four premises offered authors, listed pp 8-9 version R, demonstrate practical focus book:Many statistical learning methods relevant useful wide range academic non-academic disciplines, beyond just statistical sciences.Statistical learning viewed series black boxes.important know job performed cog, necessary skills construct machine inside box!presume reader interested applying statistical learning methods real-world problems.free PDF versions applications R Python . sure check interested learning machine learning models!","code":""},{"path":"data.html","id":"data","chapter":"3 Data","heading":"3 Data","text":"data, don’t feel rushed jump data analysis yet. steps can help know data better , often, avoid problems road. demonstrate typical steps exploring data.","code":""},{"path":"data.html","id":"data-exploratoary-analysis","chapter":"3 Data","heading":"3.1 Data Exploratoary Analysis","text":"read data, checks. use embedded mtcars example illustration.seen , command str allows see variables types. dataset, variables numerical. categorical numerical, make sure transform right type data. (Sometimes numbers saved characters, analysis correct datatype remains character.)Next, try make plots–typically histograms numerical variables barplots categorical variables.can also look paired plots see two variables perfectly correlated, cause problems regression models.Next, take look summary statistics.summaries can show, example, ranges means variables. can give better understanding values whether might data entry errors.","code":"\nlibrary(tidyverse)## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n## ✔ dplyr     1.1.4     ✔ readr     2.1.4\n## ✔ forcats   1.0.0     ✔ stringr   1.5.1\n## ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n## ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n## ✔ purrr     1.0.2     \n## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n## ✖ dplyr::filter() masks stats::filter()\n## ✖ dplyr::lag()    masks stats::lag()\n## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\ndata(\"mtcars\")\nstr(mtcars)## 'data.frame':    32 obs. of  11 variables:\n##  $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n##  $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n##  $ disp: num  160 160 108 258 360 ...\n##  $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n##  $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n##  $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n##  $ qsec: num  16.5 17 18.6 19.4 17 ...\n##  $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n##  $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n##  $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n##  $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\npar(mfrow = c(3,3), mar = c(2,2,2,2))\nfor (i in 1:ncol(mtcars)){\n  hist(mtcars[,i], main = paste0(\"Histogram of \", colnames(mtcars)[i]))\n}\npairs(mtcars)\nfor (i in 1:ncol(mtcars)){\n  print(paste0(\"***** Summaries of \", colnames(mtcars)[i],\" *****\"))\n  print(summary(mtcars[,i]))\n}## [1] \"***** Summaries of mpg *****\"\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   10.40   15.43   19.20   20.09   22.80   33.90 \n## [1] \"***** Summaries of cyl *****\"\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   4.000   4.000   6.000   6.188   8.000   8.000 \n## [1] \"***** Summaries of disp *****\"\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    71.1   120.8   196.3   230.7   326.0   472.0 \n## [1] \"***** Summaries of hp *****\"\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    52.0    96.5   123.0   146.7   180.0   335.0 \n## [1] \"***** Summaries of drat *****\"\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   2.760   3.080   3.695   3.597   3.920   4.930 \n## [1] \"***** Summaries of wt *****\"\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   1.513   2.581   3.325   3.217   3.610   5.424 \n## [1] \"***** Summaries of qsec *****\"\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   14.50   16.89   17.71   17.85   18.90   22.90 \n## [1] \"***** Summaries of vs *****\"\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  0.0000  0.0000  0.0000  0.4375  1.0000  1.0000 \n## [1] \"***** Summaries of am *****\"\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  0.0000  0.0000  0.0000  0.4062  1.0000  1.0000 \n## [1] \"***** Summaries of gear *****\"\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   3.000   3.000   4.000   3.688   4.000   5.000 \n## [1] \"***** Summaries of carb *****\"\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   1.000   2.000   2.000   2.812   4.000   8.000"},{"path":"data.html","id":"data-requirement","chapter":"3 Data","heading":"3.2 Data Requirement","text":"difficult talk data requirement general sense. considerations offered . data appropriate research questions. example, want know causal relationships, clinical trial data gold standard. , make sure sample size large enough want study. like know behavior mice, repeatedly recording behavior one mouse, even five mice, sufficient. , measurement consistent. major changes data collection methods taken consideration. Sometimes adjustment can made. best practice consider data collected ensure sufficient information data answer research questions.","code":""},{"path":"data.html","id":"strategies-for-missing-data","chapter":"3 Data","heading":"3.3 Strategies for Missing Data","text":"","code":""},{"path":"data.html","id":"removing-observations","chapter":"3 Data","heading":"3.3.1 Removing observations","text":"large dataset percentage missing data small, can simply ignore observations. Note check whether pattern missingness “missing random,” meaning reason certain observations missing pure chance. , example, observations missing pollution level high low detection ideal, ignoring observations result biased conclusions.","code":""},{"path":"data.html","id":"imputation","chapter":"3 Data","heading":"3.3.2 Imputation","text":"Imputation commonly used method missing data. linearity plausible, can use linear imputation. response variables missing, Bayesian method can fill values using posterior draws. (words, process running analysis, algorithm can predict response variable according assumed model fill .) Typically imputation done multiple times mean imputated values used.","code":""},{"path":"evaluation.html","id":"evaluation","chapter":"4 Evaluation","heading":"4 Evaluation","text":"","code":""},{"path":"evaluation.html","id":"training-vs-testing","chapter":"4 Evaluation","heading":"4.1 Training vs Testing","text":"first address concepts training testing. Instead using entire data, common split dataset training set testing set. Typically people use percentages 70% vs 30% 80% vs 20%. idea use , say, 80% data training, means run select model part data. model coefficients (can think slopes) test results testing set see well model performs. Since part data testing used training, double dipping. Sometimes people split dataset three sets: training, testing, validation. trained models used testing set model selection. validation set used end gauge model perform ’s new data.","code":""},{"path":"evaluation.html","id":"metrics","chapter":"4 Evaluation","heading":"4.2 Metrics","text":"","code":""},{"path":"evaluation.html","id":"numerical-responses","chapter":"4 Evaluation","heading":"4.2.1 Numerical Responses","text":"common metrics numerical responses include mean squared errors (MSE), bias, \\(R^2\\) (adjusted \\(R^2\\)). way calculate MSE :\n\\[MSE = \\frac{1}{n} \\sum_{=1}^n \\bigg( \\hat{y}_i - y_i \\bigg)^2,\\]\n\\(\\hat{y}_i\\) predicted outcome \\(^{th}\\) observation \\(y_i\\) \\(^{th}\\) observed outcome. metric shows, average, squared distance predictions true responses. Bias calculated \n\\[Bias = \\frac{1}{n} \\sum_{=1}^n \\bigg( \\hat{y}_i - y \\bigg).\\]\ntwo metrics seem similar, reveal different aspects model performance. general, bias shows predictions centered around truth, MSE shows whether predictions centered around truth far predictions truth. bias zero, means mean prediction goes towards truth sample size increases infinity. naturally desired property, might surprised sometimes willing accept bias reduce variance.One important formula \n\\[MSE = Bias^2 + Variance,\\]\n\n\\[Variance = \\frac{1}{n} \\sum_{=1}^n \\bigg( \\hat{y}_i - E(\\hat{y}) \\bigg)^2\\]\n\n\\[E(\\hat{y}) = \\frac{1}{n} \\sum_{=1}^n \\hat{y}_i.\\]\nskip derivation , interested readers can find derivation readily online. formula tells us , MSE large bias small, means model large variance. say, fit model multiple times, quite different results. formulas might seem technical, message important. trade-bias variance; words, free lunch. balance bias variance many methods strive achieve.","code":""},{"path":"evaluation.html","id":"categorical-responses","chapter":"4 Evaluation","heading":"4.2.2 Categorical Responses","text":"responses categorical, common way measure performance confusion matrix, shows numbers predictions correct incorrect. See examples Workflow Demonstration. metrics include sensitivity, specificity, precision, recall, metrics try combine metrics present one-number summary.","code":""},{"path":"evaluation.html","id":"overfitting","chapter":"4 Evaluation","heading":"4.3 Overfitting","text":"Overfitting means model can make good predictions available data, generalize well new data. like student memorizes past exam questions without really studying materials, , exam, student can really well questions coming past exams might poorly questions never seen . Splitting data training testing one strategy avoid overfitting. Certain ML methods less likely overfit, neural networks. strategies, early stopping, can used. point aware potential pitfall machine learning methods.","code":""},{"path":"evaluation.html","id":"cross-validation","chapter":"4 Evaluation","heading":"4.4 Cross Validation","text":"One standard way evaluation \\(k\\)-fold cross validation, commonly \\(k=5\\) \\(k=10\\). idea simple. Divide data \\(k\\) groups. time, choose \\(k-1\\) groups training, fit model last group, test data, calculate desired metrics, MSE.way, although less data used training, metrics accurate, now using data points training testing. Using metrics cross validation model selection can ensure model overfit.\nFigure 4.1: Image Source: https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n","code":""},{"path":"machine-learning-methods.html","id":"machine-learning-methods","chapter":"5 Machine Learning Methods","heading":"5 Machine Learning Methods","text":"discuss machine learning methods might find useful. Although linear regression models commonly used, skip well understood many online resources can easily located.","code":""},{"path":"machine-learning-methods.html","id":"tree-based-methods","chapter":"5 Machine Learning Methods","heading":"5.1 Tree-based Methods","text":"Tree-based methods popular ease interpretation. Essentially, algorithm tries split data subsets finding significant (consequential) variables way reduces prediction error . example, graph , variable helps reduce prediction error first level gender. words, property male female can greatly help algorithm predict survival passengers Titanic.Decision trees easy use accurate complex data; however, can go beyond one tree. use multiple trees , instance, take average predictions trees, can improve performance. idea ensemble methods. One ensemble methods, Random Forests, commonly used, including natural resources management, quite accurate many kinds data. next ’ll dive one method.","code":""},{"path":"machine-learning-methods.html","id":"random-forests","chapter":"5 Machine Learning Methods","heading":"5.1.1 Random Forests","text":"Random Forests, algorithm randomly selects smaller number, say \\(m\\), predictors total number, say \\(p\\), time tree fit. process repeated many times, example, \\(500\\) times. average (continuous responses) majority votes (discrete responses) predictions individual trees used final predictions. randomly choosing subset predictors time, Random Forests can avoid relying variables every time prevent overfitting.Even though coefficients predictors available random forests, can easily get important variables least know variables important predicting response. can also use Random Forests tool variable selection use different method fit model subset predictors chosen Random Forests.See Workflow Demonstration examples Random Forests models.","code":""},{"path":"machine-learning-methods.html","id":"other-ensemble-tree-methods","chapter":"5 Machine Learning Methods","heading":"5.1.2 Other Ensemble Tree Methods","text":"ensemble tree methods include boosting bagging. interested, take look Chapter 8 (Tree-Based Methods) Introduction Statistical Learning James et al. (2013).","code":""},{"path":"machine-learning-methods.html","id":"neural-network","chapter":"5 Machine Learning Methods","heading":"5.2 Neural Network","text":"Neural network enjoying popularity. neural network model composed input layer, hidden layers, output layer, seen . one hidden layer . enough hidden layers, model called deep learning.input layer observed predictors, hidden layers nodes contain coefficients. can think coefficients similar linear models, except linear relationships observed predictors. values derived best fit data kind cost function; essentially, values meant minimize differences observed outcome predictions. values one hidden layer passed onto next layer, nonlinear activation function called ReLU commonly used. task classification, layer right output often algorithm turn values predicted class. neural network powerful ML model, values nodes hidden layers interpretable. indeed black-box method. interested readers, check Chapter 10 Deep Learning James et al. (2013) (Introduction Statistical Learning).","code":""},{"path":"machine-learning-methods.html","id":"gaussian-process-gp","chapter":"5 Machine Learning Methods","heading":"5.3 Gaussian Process (GP)","text":"Another ML method useful natural resource management type research Gaussian Process. method, commonly called kriging spatial statistics, non-parametric, sounds like parameters model fact means can infinite number parameters. (course real model ’ll finite parameters, ’s idea.) fact parameters can increase towards infinity tells us flexible model. Essentially, GP model, quote Chapter 5 Gramacy’s Surrogates, “finite collection realizations (.e. \\(n\\) observations) modeled multivariate normal (MVN) distribution.” words, model tries learn information similar items, judging kind distance . MVN great properties. , new data point, observed data points can used make prediction .GP widely used machine learning, computer experiments, spatial statistics communities. ready-made R packages, GpGp deepgp. ’s also easy use Python. Chapter 5 (“Gaussian Process Regression”) book Surrogates Gramacy (2020) great resource interested learning Gaussian process! like see theory GP, check another classic book Gaussian Processes Machine learning Rasmussen Williams (2006).","code":""},{"path":"workflow-demonstration.html","id":"workflow-demonstration","chapter":"6 Workflow Demonstration","heading":"6 Workflow Demonstration","text":"section, use dataset exemplify typical workflow constructing ML models. skip exploratory data analysis, since already addressed aspect Data. dataset contains wine quality traits, goal predict quality wine using traits. dataset can found .","code":"\nknitr::opts_chunk$set(echo = TRUE, eval = TRUE, cache = TRUE)\nlibrary(tree)\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(rattle)\nlibrary(randomForest)"},{"path":"workflow-demonstration.html","id":"prepare-data","chapter":"6 Workflow Demonstration","heading":"6.1 Prepare Data","text":"first read data rename variables, coding easier.demonstrate construct Random Forests models continuous discrete outcomes, also transform continuous variable, wine quality, response variable, two discrete variables. One two levels: high vs low, one three levels: H, M, L. thresholds decided rather arbitrarily, can use domain knowledge gauge set thresholds.Next randomly separate dataset training set (80% rows) testing set (20% rows). seed set result can reproduced.","code":"\nwine <- read_delim(\"materials/winequality-red.csv\", delim = ';')## Rows: 1599 Columns: 12\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \";\"\n## dbl (12): fixed acidity, volatile acidity, citric acid, residual sugar, chlo...\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n# shorten variable names\nfa <- wine$`fixed acidity`\nva <- as.numeric(wine$`volatile acidity`)\nca <- as.numeric(wine$`citric acid`)\nrs <- wine$`residual sugar`\nch <- as.numeric(wine$chlorides)\nfsd <- wine$`free sulfur dioxide`\ntsd <- wine$`total sulfur dioxide`\nden <- as.numeric(wine$density)\nph <- wine$pH\nsul <- as.numeric(wine$sulphates)\nal <- wine$alcohol\nqual <- wine$quality\nwinez <- data.frame(fa, va, ca, rs, ch, fsd, tsd, den, ph, sul, al, qual)\n# collapse qual into 2 labels\nwinez$qual2 <- as.factor(ifelse(winez$qual < 6, \"low\", \"high\"))\n# collapse qual into 3 labels\nwinez$qual3 <- as.factor(ifelse(winez$qual < 5, \"L\", ifelse(winez$qual < 7, \"M\", \"H\")))\ntable(qual)## qual\n##   3   4   5   6   7   8 \n##  10  53 681 638 199  18\ntable(winez$qual2)## \n## high  low \n##  855  744\ntable(winez$qual3)## \n##    H    L    M \n##  217   63 1319\n# separate data into a training set and a test set \nset.seed(2)\ntrain <- sample(nrow(winez), nrow(winez)*.8)\nwinez_train <- winez[train,]\nwinez_test <- winez[-train,]"},{"path":"workflow-demonstration.html","id":"classification-models","chapter":"6 Workflow Demonstration","heading":"6.2 Classification Models","text":"Now construct Random Forests model two-level response. model run, calculate predictions using predict function. plot important predictors provided. can see alcohol, sulphates, volatile acidity three important predictors outcome variable. confusion matrix created, shows different metrics overall accuracy rate, sensitivity, specificity, etc.Next create model three-level outcome variable. , important predictors plotted confusion matrix included . alcohol, volatile acidity, sulphates three important predictors, order changed. overall accuracy higher two-level model.plot shows accuracy rate changes number randomly selected variables tree (denoted \\(m\\)).\nFigure 6.1: Accuracy Rates vs Number Predictors Used 2-level Variable (left) 3-level Variable (right)\n","code":"\n# random forest\nrfGrid <- expand.grid(mtry = 2:8)\n# 2-level variable\nrf_tree2 <- train(qual2 ~ fa + va + ca + rs + ch + fsd + tsd + den + ph + sul + al, data = winez_train, method = \"rf\", preProcess = c(\"center\", \"scale\"), trControl = trainControl(method = \"cv\", number = 10), tuneGrid = rfGrid)\nrf2_pred <- predict(rf_tree2, newdata = winez_test)\nrfMatrix2 <- table(rf2_pred, winez_test$qual2)\nrf2_test <- mean(rf2_pred == winez_test$qual2)\nplot(varImp(rf_tree2))\nconfusionMatrix(rf2_pred, winez_test$qual2)## Confusion Matrix and Statistics\n## \n##           Reference\n## Prediction high low\n##       high  138  25\n##       low    45 112\n##                                           \n##                Accuracy : 0.7812          \n##                  95% CI : (0.7319, 0.8253)\n##     No Information Rate : 0.5719          \n##     P-Value [Acc > NIR] : 2.968e-15       \n##                                           \n##                   Kappa : 0.5613          \n##                                           \n##  Mcnemar's Test P-Value : 0.02315         \n##                                           \n##             Sensitivity : 0.7541          \n##             Specificity : 0.8175          \n##          Pos Pred Value : 0.8466          \n##          Neg Pred Value : 0.7134          \n##              Prevalence : 0.5719          \n##          Detection Rate : 0.4313          \n##    Detection Prevalence : 0.5094          \n##       Balanced Accuracy : 0.7858          \n##                                           \n##        'Positive' Class : high            \n## \n# 3-level variable\nrf_tree3 <- train(qual3 ~ fa + va + ca + rs + ch + fsd + tsd + den + ph + sul + al, data = winez_train, method = \"rf\", preProcess = c(\"center\", \"scale\"), trControl = trainControl(method = \"cv\", number = 10), tuneGrid = rfGrid)\nrf3_pred <- predict(rf_tree3, newdata = winez_test)\nrfMatrix3 <- table(rf3_pred, winez_test$qual3)\nrf3_test <- mean(rf3_pred == winez_test$qual3)\nplot(varImp(rf_tree3))\nconfusionMatrix(rf3_pred, winez_test$qual3)## Confusion Matrix and Statistics\n## \n##           Reference\n## Prediction   H   L   M\n##          H  25   0   5\n##          L   0   0   1\n##          M  18   8 263\n## \n## Overall Statistics\n##                                           \n##                Accuracy : 0.9             \n##                  95% CI : (0.8618, 0.9306)\n##     No Information Rate : 0.8406          \n##     P-Value [Acc > NIR] : 0.001473        \n##                                           \n##                   Kappa : 0.5617          \n##                                           \n##  Mcnemar's Test P-Value : NA              \n## \n## Statistics by Class:\n## \n##                      Class: H Class: L Class: M\n## Sensitivity           0.58140 0.000000   0.9777\n## Specificity           0.98195 0.996795   0.4902\n## Pos Pred Value        0.83333 0.000000   0.9100\n## Neg Pred Value        0.93793 0.974922   0.8065\n## Prevalence            0.13437 0.025000   0.8406\n## Detection Rate        0.07812 0.000000   0.8219\n## Detection Prevalence  0.09375 0.003125   0.9031\n## Balanced Accuracy     0.78167 0.498397   0.7339\n# random forest plot: accuracy rates vs number of predictors\nrfplot1 <- plot(rf_tree2)\nrfplot2 <- plot(rf_tree3)\ngridExtra::grid.arrange(rfplot1, rfplot2, nrow = 1, ncol = 2)"},{"path":"workflow-demonstration.html","id":"prediction-models","chapter":"6 Workflow Demonstration","heading":"6.3 Prediction Models","text":"Next construct Random Forests models continuous outcome variable. first set \\(m\\) square root number predictors, commonly recommended. Confusion matrices provided continuous responses, can calculate MSEs, find important variables, show error decreases number trees constructed. three important variables alcohol, sulphates, volatile acidity.try several different numbers number variable included tree. alcohol, sulphates, volatile acidity remain three important predictors. Two plots provided show error decreases number trees.Lastly, put MSEs models together. differences small, model uses \\(m=\\sqrt{p}\\) slightly lower MSE.","code":"\n# randomforests, mtry = sqrt(11)\nrf.def.Wine <- randomForest(qual ~ fa + va + ca + rs + ch + fsd + tsd + den + ph + sul + al, data = winez_train, importance = TRUE)\nyhat.rf.Wine <- predict(rf.def.Wine, newdata = winez_test)\nrf.mtry3.testMSE <- mean((yhat.rf.Wine - winez_test$qual)^2)\nvarImp(rf.def.Wine)##      Overall\n## fa  22.11429\n## va  37.04878\n## ca  23.74687\n## rs  18.55913\n## ch  24.96786\n## fsd 21.65164\n## tsd 32.28444\n## den 27.19701\n## ph  22.36903\n## sul 43.52900\n## al  54.53284\nplot(rf.def.Wine)\n# mtry = 4\nrf.def.Wine.m4 <- randomForest(qual ~ fa + va + ca + rs + ch + fsd + tsd + den + ph + sul + al, data = winez_train, mtry = 4, importance = TRUE)\nrf.pred.m4 <- predict(rf.def.Wine.m4, newdata = winez_test)\nrf.mtry4.testMSE <- mean((rf.pred.m4 - winez_test$qual)^2)\nvarImp(rf.def.Wine.m4)##      Overall\n## fa  22.78226\n## va  39.40868\n## ca  22.22551\n## rs  16.27685\n## ch  25.12775\n## fsd 21.58168\n## tsd 30.36789\n## den 27.20655\n## ph  20.22223\n## sul 47.59070\n## al  60.54909\n# mtry = 7\nrf.def.Wine.m7 <- randomForest(qual ~ fa + va + ca + rs + ch + fsd + tsd + den + ph + sul + al, data = winez_train, mtry = 7, importance = TRUE)\nrf.pred.m7 <- predict(rf.def.Wine.m7, newdata = winez_test)\nrf.mtry7.testMSE <- mean((rf.pred.m7 - winez_test$qual)^2)\nvarImp(rf.def.Wine.m7)##      Overall\n## fa  22.31197\n## va  43.85162\n## ca  22.34412\n## rs  15.79913\n## ch  26.89172\n## fsd 22.86225\n## tsd 35.73985\n## den 28.37794\n## ph  24.39275\n## sul 55.85386\n## al  71.99840\npar(mfrow = c(1, 2))\nplot(rf.def.Wine.m4)\nplot(rf.def.Wine.m7)\nres <- data.frame(rf.mtry3.testMSE, rf.mtry4.testMSE, rf.mtry7.testMSE)\ncolnames(res) <- c(\"squre root of p\", \"4\", \"7\")\nrownames(res) <- c(\"MSE\")\nknitr::kable(res)"},{"path":"case-studies.html","id":"case-studies","chapter":"7 Case Studies","heading":"7 Case Studies","text":"Since machine learning models relatively easy construct, can least used compare results explore areas much known, hypotheses can made help guide directions process-based models. provide overviews three case studies demonstrate ML models can benefit environmental natural resource management studies.","code":""},{"path":"case-studies.html","id":"case-study-1-machine-learning-approach-for-modeling-daily-pluvial-flood-dynamics-in-agricultural-landscapes","chapter":"7 Case Studies","heading":"7.1 Case Study 1: Machine learning approach for modeling daily pluvial flood dynamics in agricultural landscapes","text":"","code":""},{"path":"case-studies.html","id":"takeaway","chapter":"7 Case Studies","heading":"7.1.1 Takeaway","text":"remote sensed images important data sources, researchers lot pre-processing. pre-processing images might seem time consuming, workflow established, studying flood areas becomes easier, long images available. one strengths ML models–process can least partially automated, data easily obtained measuring site required.","code":""},{"path":"case-studies.html","id":"summary","chapter":"7 Case Studies","heading":"7.1.2 Summary","text":"study, Fidan et al. (2023) built Random Forests model using gridded rainfall data, derived remotely sensed imagery, 2016 hurricane Matthew’s impact Kinston, North Carolina. Besides proprietary images, researchers also included readily available geospatial landscape traits models. objectives (1) developing pluvial flood dataset using imagery, (2) testing performance Random Forests models modeling flood “low-lying flat agricultural terrain,” (3) finding important predictors, (4) “generat[ing] pluvial flood time series.”outcome variable binary terms flooding. pixel treated one data point. Non-flooded areas covered 5,875,480 pixels, flooded areas 678,010 pixels. Since many non-flooded pixels flooded pixels, overall accuracy alone good performance metric, since, model always predicted pixel flooded, accuracy rate high. researchers chose metrics precision, recall, specificity, F1 scores reflect model performance different scenarios. model achieved overall accuracy 0.97 F1 score 0.69. Considering information rate (model predicts non-flooded time) around 88.5%, performance seemed satisfactory. found important variables population density, distance nearest river, height nearest drainage, distance nearest road.full paper can accessed .","code":""},{"path":"case-studies.html","id":"case-study-2-short-term-forecasting-of-fecal-coliforms-in-shellfish-growing-waters","chapter":"7 Case Studies","heading":"7.2 Case Study 2: Short-term forecasting of fecal coliforms in shellfish growing waters","text":"","code":""},{"path":"case-studies.html","id":"takeaway-1","chapter":"7 Case Studies","heading":"7.2.1 Takeaway","text":"study serves nice case study (1) demonstrates Random Forests well nonlinear relationships predictors outcomes, (2) performance least good studies, (3) findings consistent researchers known. reasons help us establish trust Random Forests models. Furthermore, Random Forests models easy cheap construct. R package caret function rf, used Chazal et al. (2024), easy use quick run, number trees reasonably chosen. important variables, readily provided caret::rf, help greatly interpretation.","code":""},{"path":"case-studies.html","id":"summary-1","chapter":"7 Case Studies","heading":"7.2.2 Summary","text":"study’s goal predict near-term (1-3 days) fecal contamination coastal shellfish growing waters. five management areas, Chazal et al. (2024) constructed five Random Forests models (1) use watershed characteristics well antecedent hydrologic meteorologic observations predict level fecal coliform (FC), (2) test whether forecasted rainfall can useful predictions, (3) find important variables. Let’s focus goals (1) (3) case study.first goal, depending management areas, \\(R^2\\) value 0.40 0.74. According Chazal et al. (2024), performance similar previous studies. settings typical ML studies. split data 80% training 20% testing used variance inflation factor (VIF) remove variables collinear, means variables correlated . third goal, found (1) antecedent rainfall, (2) river stage threshold, (3) wind high importance prediction. findings consistent current understanding. short, study demonstrates reliability ease construction interpretation Random Forests models.full paper can accessed .","code":""},{"path":"case-studies.html","id":"case-study-3-in-season-sweetpotato-yield-forecasting-using-multitemporal-remote-sensing-environmental-observations-and-machine-learning","chapter":"7 Case Studies","heading":"7.3 Case Study 3: In-season Sweetpotato Yield Forecasting using Multitemporal Remote Sensing Environmental Observations and Machine Learning","text":"","code":""},{"path":"case-studies.html","id":"takeaway-2","chapter":"7 Case Studies","heading":"7.3.1 Takeaway","text":"Although results considered moderate, study demonstrates ML models can used help decision making planning. Carbajal-Carrasco et al. (2024) state, “Even though ML models unable explain underlying processes, can surpass predictive accuracy process-based models, making ML algorithms particularly useful yield forecasting scales often computationally prohibitive process-based models.” Using remote sensing data considering multitude predictor sets, study tested find best combination predictors, best aggregation periods, optimal timing constructing models. found end mid-season optimal time constructing models, leaving four eight weeks planning. One can assume examination inclusion predictors, models can give reliable forecasting advance. models highly applicable fields help policy making, process planning, even disaster preparedness.","code":""},{"path":"case-studies.html","id":"summary-2","chapter":"7 Case Studies","heading":"7.3.2 Summary","text":"Using stationary temporal predictors multi-temporal remote sensing data make early yield forecasting, Carbajal-Carrasco et al. (2024) used four ML methods–Random Forest Regression (RFR), Artificial Neural Networks (ANN), Support Vector Machine (SVM), Extreme Gradient Boosting (XGB)–construct sweetpotato yield models county level around Coastal Plain North Carolina 2008 2022. Besides primary goal predict yield, authors also aimed (1) identify key predictors variable selection, (2) implement four ML methods, (3) determine optimal aggregation periods temporal variables, (4) evaluate early season models can reliably predict end--season yields. predictors considered included topography soil traits (elevation, slope, aspect, sand, clay, pH, cation exchange capacity, bulk density, nitrogen, soil organic carbon), weather (maximum minimum temperature around planting, precipitation) vegetation greenness (NDVI). considered 16- 32-days time frames aggregate data well comparing model performance early, mid, late models. used Boruta method variable selection.authors chose Random Forest Regression algorithm 16-day composite predictors using early- mid-growing season best model. \\(R^2\\) value \\(0.44\\) RMSE (root mean squared error) \\(3.53 t.ha^{-1}\\). authors describe two metrics acceptable forecasting. Elevation found important predictor. also conclude best time run model end mid-season, approximately four eight weeks harvest. authors cite small sample size (95 records 17 counties) major limitation propose predictors (e.g. solar-induced chlorophyll fluorescence) ML models (e.g. Deep Learning) improve performance.full paper can accessed .","code":""},{"path":"ethical-considerations.html","id":"ethical-considerations","chapter":"8 Ethical Considerations","heading":"8 Ethical Considerations","text":"Ethics might sound heavy, section mainly ensuring analysis carried responsible reproducible way. concerns unique machine learning models, complexity ML methods makes even important think issues.","code":""},{"path":"ethical-considerations.html","id":"rigor","chapter":"8 Ethical Considerations","heading":"8.1 Rigor","text":"researchers, responsible findings. Constructing ML models similar using statistical methods. one goes combinations predictors fits method many, many times, one models bound “statistical significant” result. thus important report models constructed use multiple testing adjustment applicable (see Chapter 13 “Multiple Testing” Introduction Statistical Learning James et al. (2013)).","code":""},{"path":"ethical-considerations.html","id":"reproducibility","chapter":"8 Ethical Considerations","heading":"8.2 Reproducibility","text":"allow others reproduce work, important provide enough details terms methods, data processing, code implementation, etc. also encouraged code data available repository. parts data shared publicly, helps provide simulated data set. GitHub common choice purpose. short introduction use GitHub code sharing.Another aspect reproducibility might surprising. Try use programming scripts rather drag--drop software. Starting reading data, write script read, clean, wrangle data. scripts can preserve steps data analysis. future, remember changed data arrived p-value, scripts can show details, drag--drop software leave trace.Note best practice read data programming environment make data cleaning merging script. can save cleaned version different file, don’t change original file raw data.","code":""},{"path":"ethical-considerations.html","id":"decision-making","chapter":"8 Ethical Considerations","heading":"8.3 Decision making","text":"Since research related environmental sciences natural resources likely affect decision making, now address topics.","code":""},{"path":"ethical-considerations.html","id":"uncertainty-qualification","chapter":"8 Ethical Considerations","heading":"8.3.1 Uncertainty qualification","text":"supervised ML models can provide point estimates, can quantify uncertainty. , however, important show confident model estimates. conclusion study affect important policy change, crucial present full picture findings, include uncertainty quantification. wildly different whether model 20% 95% confident answer, instance.","code":""},{"path":"ethical-considerations.html","id":"interpretability","chapter":"8 Ethical Considerations","heading":"8.3.2 Interpretability","text":"models, neural networks, highly efficient, like black boxes lend easily interpretablity. case neural networks, even able find weights hidden layers, really way interpret . ensure model arrives reasonable conclusion, might consider using model interpretable, linear regression tree-based methods. way, experts domain knowledge can examine whether conclusion makes sense. words, findings ML models can add researchers’ understanding field rather throwing answer easily interpreted.","code":""},{"path":"appendix.html","id":"appendix","chapter":"9 Appendix","heading":"9 Appendix","text":"","code":""},{"path":"appendix.html","id":"dos-and-donts","chapter":"9 Appendix","heading":"9.1 Do’s and Don’ts","text":"provide tips build machine learning models.","code":""},{"path":"appendix.html","id":"dos","chapter":"9 Appendix","heading":"9.1.1 Do’s","text":"consider whether data appropriate research questions.data exploratory analysis jumping analysis. Look summary statistics make plots familiarize data.Document process reasonable details, researchers can reproduce study needed.Along line, write scripts code, add comments along way.publication, explain result entails limitations model.possible, use interpretable /parsimonious models. Think Occam’s razor.Make data code available others possible.","code":""},{"path":"appendix.html","id":"donts","chapter":"9 Appendix","heading":"9.1.2 Don’ts","text":"Don’t alter raw data. Use script process data instead.Don’t interpret result. example, samples come one geographic area, might able generalize result areas.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
